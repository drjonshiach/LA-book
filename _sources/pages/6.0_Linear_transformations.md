(linear-transformations-chapter)=

:::{index} Linear transformations
:::

# Linear Transformations

You will already be familiar with the use of <a href="https://en.wikipedia.org/wiki/Function_(mathematics)" target="_blank">functions</a> in mathematics to study sets and the **mapping** from a set of inputs set to another set of outputs. The notation used to denote functions is of the form $f: X \to Y$ where $f$ is the name of the function, $X$ is the set of inputs known as the **domain** and $Y$ is a member of the set of outputs known as the **codomain**. The mapping which defines the relationship between the domain and codmain is defined using $y = f(x)$ where $x$ is a member of the domain and $y$ is a member of the codomain. 

In linear algebra we study the linear mapping of a set of vectors to another set of vectors so we define $T: V \to W$ where $V$ and $W$ are vector spaces and the mapping from an input vector $\mathbf{u} \in V$ to an output vector $\mathbf{w} \in W$ is given by $\mathbf{w} = T(\mathbf{u})$.

Linear transformations have lots of uses in mathematics and computing. A good example is in the field of computer graphics and computer games where they are fundamental to the manipulation and visualisation of three-dimensional objects.

We begin with the formal definition of a linear transformation.

:::{prf:definition} Linear transformation
:label: linear-transformation-definition

If $V$ and $W$ are two vector spaces over the same field $F$ then by a **linear transformation** (or **linear mapping**) is a mapping $T: V \to W$ that for any two vectors $\mathbf{u}, \mathbf{v} \in V$ and any scalar $\alpha \in F$ the following conditions hold

- addition operation: $T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})$;
- scalar multiplication:  $T(\alpha \mathbf{u}) = \alpha T(\mathbf{u})$.

The result of applying a linear transformation to an object is known as the **image**.
:::

For example, let $V = \mathbb{R}^2$ and $W = \mathbb{R}^3$ then $T : V \to W$ defined by $T : (x, y) \mapsto (x, y, 0)$ is a linear transformation. Let $\mathbf{u} = (u_1, u_2), \mathbf{v} = (v_1, v_2) \in \mathbb{R}^2$ and $\alpha \in F$ then

$$ \begin{align*}
    T \left( \begin{pmatrix} u_1 \\ u_2 \end{pmatrix} + \begin{pmatrix} v_1 \\ v_2 \end{pmatrix} \right)
    &= T \begin{pmatrix} u_1 + v_1 \\ u_2 + v_2 \end{pmatrix}
    = \begin{pmatrix} u_1 + v_1 \\ u_2 + v_2 \\ 0 \end{pmatrix} \\
    &= \begin{pmatrix} u_1 \\ v_1 \\ 0 \end{pmatrix} + \begin{pmatrix} u_2 \\ v_2 \\ 0 \end{pmatrix}
    = T \begin{pmatrix} u_1 \\ u_2 \end{pmatrix} + T \begin{pmatrix} v_1 \\ v_2 \end{pmatrix}.
\end{align*} $$

Similarly

$$ T \left( \alpha \begin{pmatrix} u_1 \\ u_2 \end{pmatrix} \right)
    = T \begin{pmatrix} \alpha u_1 \\ \alpha u_2 \end{pmatrix} 
    = \begin{pmatrix} \alpha u_1 \\ \alpha u_2 \\ 0 \end{pmatrix}
    = \alpha \begin{pmatrix} u_1 \\ u_2 \\ 0 \end{pmatrix}
    = \alpha T \begin{pmatrix} u_1 \\ u_2 \end{pmatrix}. $$

To show whether a transformation is a linear transformation can combine both conditions from the {prf:ref}`definition of a linear transformation<linear-transformation-definition>` to show that

$$ T(\mathbf{u} + \alpha \mathbf{v}) = T(\mathbf{u}) + \alpha T(\mathbf{v}). $$(linear-transformation-condition-equation)

::::{prf:example}
:label: linear-transformation-example

Determine which of the following transformations are linear transformations

(i) &emsp; $T: \mathbb{R}^3 \to \mathbb{R}^2$ defined by $T: (x, y, z) \mapsto (x, y)$

:::{dropdown} Solution
Let $(x_1, y_1, z_1), (x_2, y_2, z_2) \in \mathbb{R}^3$ and $\alpha \in F$ then

$$ \begin{align*}
    &T \left( \begin{pmatrix} x_1 \\ y_1 \\ z_1 \end{pmatrix} + \alpha \begin{pmatrix} x_2 \\ y_2 \\ z_2 \end{pmatrix}
    \right) \\
    &= T \begin{pmatrix} x_1 + \alpha x_2 \\ y_1 + \alpha y_2 \\ z_1 + \alpha z_2 \end{pmatrix} \\
    &= \begin{pmatrix} x_1 + \alpha x_2 \\  y_1 + \alpha y_2 \end{pmatrix} \\
    &= \begin{pmatrix} x_1 \\ y_1 \end{pmatrix} + \alpha \begin{pmatrix}  x_2 \\ y_2 \end{pmatrix} \\
    &= T\begin{pmatrix} x_1 \\ y_1 \\ z_1 \end{pmatrix} + \alpha T\begin{pmatrix} x_2 \\ y_2 \\ z_2 \end{pmatrix}.
\end{align*} $$

So $T: (x, y, z) \mapsto (x, y)$ is a linear transformation.
:::

(ii) &emsp; $T: \mathbb{R}^3 \to \mathbb{R}^2$ defined by $T: (x, y, z) \mapsto (x + 3, y)$

:::{dropdown} Solution
Let $(x_1, y_1, z_1)$, $(x_2, y_2, z_2) \in \mathbb{R}^3$ and $\alpha \in F$ then

$$ \begin{align*}
    T \left( \begin{pmatrix} x_1 \\ y_1 \\ z_1 \end{pmatrix} + \alpha \begin{pmatrix} x_2 \\ y_2 \\ z_2 \end{pmatrix} \right)
    &= T \begin{pmatrix} x_1 + \alpha x_2 \\ y_1 + \alpha y_2 \\ z_1 + \alpha z_2 \end{pmatrix} \\
    &= \begin{pmatrix} x_1 + \alpha x_2 + 3 \\ y_1 + \alpha y_2 \end{pmatrix} \\
    &= \begin{pmatrix} x_1 + 3 \\ y_1 \end{pmatrix} + \begin{pmatrix} \alpha x_2 \\ \alpha y_2 \end{pmatrix} \\
    &\neq T\begin{pmatrix} x_1 \\ y_1 \\ z_1 \end{pmatrix} + \alpha T \begin{pmatrix} x_2 \\ y_2 \\ z_2 \end{pmatrix}.
\end{align*} $$

So $T: (x, y, z) \mapsto (x + 3, y)$ is not a linear transformation. Note that we could have shown this by a counterexample, e.g., let $(1, 0, 0), (2, 0, 0) \in \mathbb{R}^3$ then by the first condition the {prf:ref}`definition of a linear transformation<linear-transformation-definition>`

$$ \begin{align*}
    T\left( \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix} + \begin{pmatrix} 2 \\ 0 \\ 0 \end{pmatrix} \right)
    &= T\begin{pmatrix} 3 \\ 0 \\ 0 \end{pmatrix} 
    = \begin{pmatrix} 6 \\ 0 \end{pmatrix}, \\
    T \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix} + T \begin{pmatrix} 2 \\ 0 \\ 0 \end{pmatrix}
    &= \begin{pmatrix} 4 \\ 0 \\ 0 \end{pmatrix} + \begin{pmatrix} 5 \\ 0 \\ 0 \end{pmatrix}
    = \begin{pmatrix} 9 \\ 0 \end{pmatrix}.
\end{align*} $$
:::

(iii) &emsp; $T: P(\mathbb{R}) \to P(\mathbb{R})$ defined by $T: T(x) \mapsto T(x) \dfrac{\mathrm{d}}{\mathrm{d}x} T(x)$

:::{dropdown} Solution

Let $x^2 \in P(\mathbb{R})$ and $2 \in F$ then 

$$ T(2x^2) = 2x^2(4x) = 8x^3 \neq 2T(x^2) = 2(x^2)(2x) = 4x^3, $$

so $T: T(x) \mapsto T(x) \dfrac{\mathrm{d}}{\mathrm{d}x} T(x)$ is not a linear transformation.
:::
::::

(transformation-matrix-section)=

:::{index} Linear transformations ; transformation matrices
:::

## Transformation matrices

For convenience we tend to use matrices to represent linear transformations. Let $T: V \to W$ be a linear transformation from the vector spaces $V$ to $W$. If $\{\mathbf{v}_1, \mathbf{v}_2, \ldots, \mathbf{v}_n\}$ is a basis for $V$ then for a vector $\mathbf{u} \in V$

$$ \mathbf{u} = u_1 \mathbf{v}_1 + u_2 \mathbf{v}_2 + \cdots + u_n \mathbf{v}_n, $$

and by the {prf:ref}`definition of a linear transformation<linear-transformation-definition>`

$$ T(\mathbf{u}) = u_1 T(\mathbf{v}_1) + u_2 T(\mathbf{v}_2) + \cdots + u_n T(\mathbf{v}_n), $$

so $T(\mathbf{u})$ depends on the vectors $T(\mathbf{v}_1), T(\mathbf{v}_2), \ldots, T(\mathbf{v}_n)$. We can write this as the matrix equation

$$ \begin{align*}
    T(\mathbf{u}) &= \begin{pmatrix} 
        \uparrow & \uparrow & & \uparrow \\
        T(\mathbf{v}_1) & T(\mathbf{v}_2) & \cdots & T(\mathbf{v}_n) \\
        \downarrow & \downarrow & & \downarrow
    \end{pmatrix}
    \begin{pmatrix} u_1 \\ u_2 \\ \vdots \\ u_n \end{pmatrix} \\
    &= A \mathbf{u}.
\end{align*} $$

In other words we can apply a linear transformation simply by multiplying $\mathbf{u}$ by a matrix $A$.

:::{prf:definition} Transformation matrix
:label: transformation-matrix-definition

Let $T : V \to W$ be a linear transformation and $A$ be a matrix such that

$$ A = \begin{pmatrix} 
    \uparrow & \uparrow & & \uparrow \\
    T(\mathbf{v}_1) & T(\mathbf{v}_2) & \cdots & T(\mathbf{v}_n) \\
    \downarrow & \downarrow & & \downarrow
\end{pmatrix} $$

then

$$ T(\mathbf{u}) = A\mathbf{u}. $$

$A$ is said to be the **matrix representation of the linear transformation** $T$ (also known as the **transformation matrix**).
:::

::::{prf:example}
:label: transformation-matrix-example

A linear transformation $T:\mathbb{R}^2 \to \mathbb{R}^2$ is defined by $T: (x, y) \mapsto (3x + y, x + 2y)$. Calculate the transformation matrix and use it to calculate $T(1, 1)$.

:::{dropdown} Solution

Since we are mapping from $\mathbb{R}^2$ the transformation matrix is

$$ A = \begin{pmatrix} T(\mathbf{e}_1) & T(\mathbf{e}_2) \end{pmatrix} $$

Applying the transformation to the standard basis vectors

$$ \begin{align*}
    T(\mathbf{e}_1) = T\begin{pmatrix} 1 \\ 0 \end{pmatrix} 
    = \begin{pmatrix} 3(1) + 0 \\ 1 + 2(0) \end{pmatrix} 
    =  \begin{pmatrix} 3 \\ 1 \end{pmatrix}, \\
    T(\mathbf{e}_2) = T\begin{pmatrix} 0 \\ 1 \end{pmatrix} 
    = \begin{pmatrix} 3(0) + 1 \\ 0 + 2(1) \end{pmatrix} 
    = \begin{pmatrix} 1 \\ 2 \end{pmatrix},
\end{align*} $$

so the transformation matrix is

$$ A &= \begin{pmatrix} 3 & 1 \\ 1 & 2 \end{pmatrix}. $$

Applying the transformation matrix to $(1, 1)$
$$ T\begin{pmatrix} 1 \\ 1 \end{pmatrix} = A \cdot \begin{pmatrix} 1 \\ 1 \end{pmatrix} =  
    \begin{pmatrix} 3 & 1 \\ 1 & 2 \end{pmatrix} 
    \begin{pmatrix} 1 \\ 1 \end{pmatrix} = 
    \begin{pmatrix} 4 \\ 3 \end{pmatrix}. $$
:::
::::

The affects of the linear transformation from {prf:ref}`linear-transformation-example` is illustrated in {numref}`linear-transformation-figure`. Note that the transformation $T$ can be thought of as changing the basis of the vector space. The unit square with respect to the basis $\{\mathbf{e}_1, \mathbf{e}_1\}$ has been transformed into a unit parallelogram with respect to the basis $\{ T(\mathbf{e}_1), T(\mathbf{e}_2)\}$.

:::{figure} /images/linear_transformation.svg
:name: linear-transformation-figure
:width: 400

The affect of applying a linear transformation $T: (x,y) \mapsto (3x + y, x + 2y)$ to the vector $(1,1)$.
:::

## Finding the transformation matrix from a set of images

The calculation of the transformation matrix in {prf:ref}`transformation-matrix-example` was straightforward as we knew what the transformation was. This will not always be a the case and we may know what the output (known as the image) of the transformation is but not the transformation itself. Consider a linear transformation $T: \mathbb{R}^n \to \mathbb{R}^m$ applied to vectors $u_1, u_2, \ldots, u_n$. If $A$ is the transformation matrix for $T$ then

$$ \begin{align*}
    A
    \begin{pmatrix}
        \uparrow & \uparrow & & \uparrow \\
        \mathbf{u}_1 & \mathbf{u}_2 & \cdots & \mathbf{u}_n \\
        \downarrow & \downarrow & & \downarrow
    \end{pmatrix} = 
    \begin{pmatrix}
        \uparrow & \uparrow & & \uparrow \\
        T(\mathbf{u}_1) & T(\mathbf{u}_2) & \cdots & T(\mathbf{u}_n) \\
        \downarrow & \downarrow & & \downarrow
    \end{pmatrix}
\end{align*} $$

therefore

$$ \begin{align*}
    A &=  
    \begin{pmatrix}
        \uparrow & \uparrow & & \uparrow \\
        T(\mathbf{u}_1) & T(\mathbf{u}_2) & \cdots & T(\mathbf{u}_n) \\
        \downarrow & \downarrow & & \downarrow
    \end{pmatrix}
    \begin{pmatrix}
        \uparrow & \uparrow & & \uparrow \\
        \mathbf{u}_1 & \mathbf{u}_2 & \cdots & \mathbf{u}_n \\
        \downarrow & \downarrow & & \downarrow
    \end{pmatrix}^{-1}
\end{align*} $$

:::{prf:theorem} Determining the linear transformation given the inputs and image vectors
:label: finding-transformation-matrix-theorem

Given a linear transformation $T: \mathbb{R}^n \to \mathbb{R}^m$ applied to a set of $n$ vectors $\mathbf{u}_1, \mathbf{u}_2, \ldots, \mathbf{u}_n$ with known image vectors $T(\mathbf{u}_1), T(\mathbf{u}_2), \ldots, T(\mathbf{u}_n)$ then the transformation matrix $A$ for $T$ is

$$ A = (T(\mathbf{u}_1), T(\mathbf{u}_2), \ldots, T(\mathbf{u}_n)) \cdot (\mathbf{u}_1, \mathbf{u}_2, \ldots, \mathbf{u}_n)^{-1}. $$(determining-the-transformation-matrix)
:::

::::{prf:example}
:label: transformation-matrix-example-2

Determine the transformation matrix $A$ for the linear transformation $T$ such that

$$ \begin{align*}
    T\begin{pmatrix} 1 \\ 1 \end{pmatrix} &= \begin{pmatrix} 4 \\ 3 \end{pmatrix}, &
    T\begin{pmatrix} 1 \\ 2 \end{pmatrix} &= \begin{pmatrix} 5 \\ 5 \end{pmatrix}.
\end{align*} $$

:::{dropdown} Solution

Using Gauss-Jordan elimination to determine the inverse of $(\mathbf{u}_1, \mathbf{u}_2)$

$$ \begin{align*}
    & \left( \begin{array}{rr|rr} 
        1 & 1 & 1 & 0 \\
        1 & 2 & 0 & 1
    \end{array} \right)
    \begin{array}{l} \\ R_2 - R_1 \end{array}  \\ \\ 
    \longrightarrow \quad &
    \left( \begin{array}{rr|rr} 
        1 & 1 & 1 & 0 \\
        0 & 1 & -1 & 1
    \end{array} \right)
    \begin{array}{l} R_1 - R_2 \\ \phantom{x} \end{array}  \\ \\
    \longrightarrow \quad &
    \left( \begin{array}{rr|rr} 
        1 & 0 & 2 & -1 \\
        0 & 1 & -1 & 1
    \end{array} \right)
\end{align*} $$

so $(\mathbf{u}_1, \mathbf{u}_2)^{-1} = \begin{pmatrix} 2 & -1 \\ -1 & 1 \end{pmatrix}$. Right multiplying the image matrix

$$ \begin{align*}
    A &= \begin{pmatrix} 4 & 5 \\ 3 & 5 \end{pmatrix} \begin{pmatrix} 2 & -1 \\ -1 & 1 \end{pmatrix}
    = \begin{pmatrix} 3 & 1 \\ 1 & 2 \end{pmatrix}.
\end{align*} $$

This is the transformation matrix from {prf:ref}`transformation-matrix-example`.
:::
::::

:::{index} Linear transformations ; inverse transformation
:::

## Inverse linear transformation

:::{prf:definition} Inverse linear transformation
:label: inverse-transformation-definition

Let $T: V \to W$ be a linear transformation with the transformation matrix $A$ then $T$ has an inverse transformation denoted by $T^{-1}: W \to V$ which reverses the affects of $T$. If $\mathbf{u} \in V$ and $\mathbf{v} \in W$ then

$$ \begin{align*}
    \mathbf{v} &= A \mathbf{u} \\
    \therefore \mathbf{u} & = A^{-1}\mathbf{v},
\end{align*} $$

where $A^{-1}$ is the transformation matrix for $T^{-1}$.
:::

::::{prf:example}
:label: inverse-transformation-example

Determine the inverse of the transformation $T: \mathbb{R}^2 \to \mathbb{R}^2$ defined by $T(x, y) \mapsto (3 x + y, x + 2 y)$ and calculate $T^{-1}(4, 3)$.

:::{dropdown} Solution
We saw in {prf:ref}`transformation-matrix-example` that the transformation matrix for $T$ is

$$ A = \begin{pmatrix} 3 & 1 \\ 1 & 2 \end{pmatrix}, $$

which has the inverse

$$ A^{-1} = \begin{pmatrix} \frac{2}{5} & -\frac{1}{5} \\ -\frac{1}{5} & \frac{3}{5} \end{pmatrix}. $$

Determining the inverse transformation

$$ \begin{align*}
    T^{-1}\begin{pmatrix} x \\ y \end{pmatrix} &= A^{-1} \cdot \begin{pmatrix} x \\ y \end{pmatrix} =
    \begin{pmatrix} \frac{2}{5} & -\frac{1}{5} \\ -\frac{1}{5} & \frac{3}{5} \end{pmatrix}
    \begin{pmatrix} x \\ y \end{pmatrix} \\
    &= \begin{pmatrix} \frac{2}{5}x - \frac{1}{5}y \\ -\frac{1}{5}x + \frac{3}{5}y \end{pmatrix}.
\end{align*} $$

Calculating $T^{-1}(4, 3)$

$$ \begin{align*}
    A^{-1} \begin{pmatrix} 4 \\ 3 \end{pmatrix} &=
    \begin{pmatrix} \frac{2}{5} & -\frac{1}{5} \\ -\frac{1}{5} & \frac{3}{5} \end{pmatrix}
    \begin{pmatrix} 4 \\ 3 \end{pmatrix} 
    = \begin{pmatrix} 1 \\ 1 \end{pmatrix}.
\end{align*} $$
:::
::::
